{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import snowflake.connector\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Snowflake Connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Environmental Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Fetch Snowflake credentials from environment variables\n",
    "snowflake_user = os.getenv('SNOWFLAKE_USER')\n",
    "snowflake_role = os.getenv('SNOWFLAKE_ROLE')\n",
    "snowflake_password = os.getenv('SNOWFLAKE_PASSWORD')\n",
    "snowflake_account = os.getenv('SNOWFLAKE_ACCOUNT')\n",
    "snowflake_warehouse = os.getenv('SNOWFLAKE_WAREHOUSE')\n",
    "snowflake_database = os.getenv('SNOWFLAKE_DATABASE')\n",
    "snowflake_schema = os.getenv('SNOWFLAKE_SCHEMA')\n",
    "snowflake_product_status_cdc = os.getenv('SNOWFLAKE_PRODUCT_STATUS_CDC')\n",
    "snowflake_product_status_hst = os.getenv('SNOWFLAKE_PRODUCT_STATUS_HST')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiating SCD Type 2 Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Warehouse, Database, and Schema in Snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Warehouse\n",
    "use_snowflake_warehouse = f\"ALTER WAREHOUSE {snowflake_warehouse.upper()} RESUME;\"\n",
    "\n",
    "# Use Database\n",
    "use_snowflake_database = f\"USE DATABASE {snowflake_database.upper()};\"\n",
    "\n",
    "# Use Schema\n",
    "use_snowflake_schema = f\"USE SCHEMA {snowflake_database.upper()}.{snowflake_schema.upper()};\"\n",
    "\n",
    "# Use Role\n",
    "use_snowflake_role = f\"USE ROLE {snowflake_role.upper()};\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Tables and Inserting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create PRODUCT_STATUS_CDC table\n",
    "# create_table_product_status_cdc = f\"\"\"\n",
    "# CREATE OR REPLACE TABLE {snowflake_database.upper()}.{snowflake_schema.upper()}.{snowflake_product_status_cdc.upper()} (\n",
    "#     PRODUCT_KEY NUMBER(38,0),\n",
    "#     STATUS NUMBER(38,0),\n",
    "#     CHANGE_TYPE VARIANT,\n",
    "#     CHANGE_TIME TIMESTAMP_NTZ(9),\n",
    "#     CDC_LOG_POSITION NUMBER(38,0)\n",
    "# );\n",
    "# \"\"\"\n",
    "\n",
    "# # Create PRODUCT_STATUS_HST table\n",
    "# create_table_product_status_hst = f\"\"\"\n",
    "# CREATE OR REPLACE TABLE {snowflake_database.upper()}.{snowflake_schema.upper()}.{snowflake_product_status_hst.upper()} (\n",
    "#     PRODUCT_STATUS_SCD_KEY NUMBER(38,0),\n",
    "#     PRODUCT_STATUS_PRODUCT_KEY NUMBER(38,0),\n",
    "#     PRODUCT_STATUS_STATUS NUMBER(38,0),\n",
    "#     SCD_START_TIME TIMESTAMP_NTZ(9),\n",
    "#     SCD_END_TIME TIMESTAMP_NTZ(9)\n",
    "# );\n",
    "# \"\"\"\n",
    "\n",
    "# insert_data_product_status_cdc = f\"\"\"\n",
    "# INSERT INTO {snowflake_database.upper()}.{snowflake_schema.upper()}.{snowflake_product_status_cdc.upper()} (PRODUCT_KEY, STATUS, CHANGE_TYPE, CHANGE_TIME, CDC_LOG_POSITION) VALUES\n",
    "#     (1, 10, 'insert', '2019-01-01 10:00:00', 1),\n",
    "#     (1, 10, 'insert', '2019-01-01 10:00:00', 1),\n",
    "#     (1, 10, 'update', '2019-01-01 10:30:00', 2),\n",
    "#     (1, 20, 'update', '2019-01-01 11:00:00', 3),\n",
    "#     (1, 20, 'delete', '2019-01-01 12:00:00', 4),\n",
    "#     (1, 10, 'insert', '2019-01-01 14:00:00', 5);\n",
    "# \"\"\"\n",
    "\n",
    "# Insert data into PRODUCT_STATUS_HST table\n",
    "# insert_data_product_status_hst = f\"\"\"\n",
    "# INSERT INTO {snowflake_database.upper()}.{snowflake_schema.upper()}.{snowflake_product_status_hst.upper()} (PRODUCT_STATUS_SCD_KEY, PRODUCT_STATUS_PRODUCT_KEY, PRODUCT_STATUS_STATUS, SCD_START_TIME, SCD_END_TIME) VALUES\n",
    "#     (1, 1, 10, '2019-01-01 10:00:00', '2019-01-01 11:00:00'),\n",
    "#     (2, 1, 20, '2019-01-01 11:00:00', '2019-01-01 12:00:00'),\n",
    "#     (3, 1, 10, '2019-01-01 14:00:00', '2999-01-01 00:00:00');\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing Stored Procedure for SCD Type 2 over CDC Stream Set\n",
    "* Goal: To create a stored procedure that will handle both scenarios\n",
    "    * Processing all data\n",
    "    * processing data starting from a specific `cdc_log_position`\n",
    "* Ensuring Idempotency (supports reprocessing) -> `MERGE INTO`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stored_procedure_name = f\"PROCESS_CDC_SCD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Just the internal query for debugging purposes\n",
    "# -- Step 0: Check the CDC table\n",
    "# SELECT * FROM CAIOCVELASCO.DATA_ENGINEER.PRODUCT_STATUS_CDC;\n",
    "\n",
    "# -- Step 1: Deduplicate records from the CDC stream\n",
    "# -- Here, we deduplicate the CDC table, selecting only unique records from the CDC table\n",
    "# -- Solved issue: \"at least once semantics\" (\"We may receive the same exact cdc record twice or more times\")\n",
    "# WITH \n",
    "#     deduplicated_cdc AS (\n",
    "#         SELECT DISTINCT\n",
    "#             product_key,\n",
    "#             status,\n",
    "#             json_extract_path_text(change_type, 'type') AS change_type,\n",
    "#             change_time,\n",
    "#             cdc_log_position\n",
    "#         FROM CAIOCVELASCO.DATA_ENGINEER.PRODUCT_STATUS_CDC\n",
    "#         WHERE change_time IS NOT NULL\n",
    "    \n",
    "# ), -- select * from deduplicated_cdc;\n",
    "\n",
    "# -- Step 2: Detect the changes that need to be captured for a given product_key\n",
    "# -- Here, we want to track changes in status for a given product\n",
    "# -- For a given product:\n",
    "# -- If inserted or updated, it will be included in the SCD.\n",
    "# -- If it was deleted, it also must be tracked in the SCD, but in this case hash needs to include the 'cdc_log_position' to differentiate (CASE method below) or we won't capture this case in the value_changed column   \n",
    "# hash_table_1 AS (\n",
    "#     SELECT *,\n",
    "#         -- HASH(product_key, status) AS _hash_test,\n",
    "#         CASE \n",
    "#             WHEN change_type != 'DELETE' THEN HASH(product_key, status) -- Same hash for the same status if not a DELETE\n",
    "#             ELSE HASH(product_key, status, change_type)                 -- Different hash if DELETE\n",
    "#         END AS _hash_1,\n",
    "#         LAG(_hash_1) OVER (PARTITION BY product_key ORDER BY cdc_log_position) AS _previous_hash_1, -- Compare hash within the same product_key\n",
    "#         -- COALESCE(_hash_test != _previous_hash_1, TRUE) AS _valued_changed_test,\n",
    "#         COALESCE(_hash_1 != _previous_hash_1, TRUE) AS _valued_changed_1 -- Flag if there is an effective change\n",
    "#     FROM deduplicated_cdc\n",
    "# ),-- select * from hash_table_1;\n",
    "\n",
    "# -- Step 3: Intermediate table before the SCD logic \n",
    "# -- Here, for a given product, we filter for all historical rows where changes might have happened (the ones that need to be present in the SCD table)\n",
    "# -- We made sure to also include the DELETE cases\n",
    "# -- We also brought the change_time as an initial step towards scd_start_time and scd_end_time\n",
    "# hash_table_2 AS (\n",
    "#     SELECT * exclude (_hash_1, _previous_hash_1, _valued_changed_1)\n",
    "#     FROM hash_table_1 \n",
    "#     WHERE _valued_changed_1 = 'TRUE'\n",
    "# ), -- select * from hash_table_2;\n",
    "\n",
    "# -- Step 4: Create is_active column based on the previous status and current change_type\n",
    "# -- Here, we want to flag DELETEs as not active because all we need is to close the previous status, so don't need to keep the row where change_type = DELETE\n",
    "# -- For now, we will not filter the IS_ACTIVe = TRUE values because we need the DELETE rows to close the previous record\n",
    "# final_table AS (\n",
    "#     SELECT *,\n",
    "#         -- Use LAG to get the previous status in this step\n",
    "#         LAG(status) OVER (PARTITION BY product_key ORDER BY change_time) AS _previous_status, -- Get previous status\n",
    "#         -- Set is_active to FALSE if the previous status is the same and change_type is DELETE\n",
    "#         CASE\n",
    "#             WHEN change_type = 'DELETE' THEN FALSE\n",
    "#             ELSE TRUE\n",
    "#         END AS is_active\n",
    "#     FROM hash_table_2\n",
    "# ), -- select * from final_table;\n",
    "\n",
    "# -- Step 5: Opening and Closing rows (scd_start_time and scd_end_time) \n",
    "# -- Here, we close previous records with the respective scd_start_time and scd_end_time based on change_time\n",
    "# scd_table AS (\n",
    "#     SELECT \n",
    "#         product_key                        AS product_status_product_key, -- Foreign key to product_dm table\n",
    "#         status                             AS product_status_status,      -- Status of the product for this SCD record\n",
    "#         CAST(change_time AS TIMESTAMP_NTZ) AS scd_start_time,             -- Start time of the SCD record in TIMESTAMP_NTZ\n",
    "#         -- Set end time based on next change_time or default to '2999-01-01 00:00:00' if no further changes\n",
    "#         CASE \n",
    "#             WHEN is_active = FALSE THEN CAST(change_time AS TIMESTAMP_NTZ)\n",
    "#             ELSE CAST(\n",
    "#                 COALESCE(\n",
    "#                     LEAD(change_time) OVER (PARTITION BY product_key ORDER BY change_time),\n",
    "#                     TIMESTAMP '2999-01-01 00:00:00'\n",
    "#                 ) AS TIMESTAMP_NTZ\n",
    "#             )\n",
    "#         END AS scd_end_time,\n",
    "#         is_active,\n",
    "#         cdc_log_position\n",
    "#     FROM final_table\n",
    "# ) -- select * from scd_table;\n",
    "\n",
    "# -- Select only the active rows for the final SCD result (getting rid of the DELETE rows)\n",
    "# -- Add sequential surrogate key after filtering\n",
    "# SELECT \n",
    "#     ROW_NUMBER() OVER (ORDER BY product_status_product_key, scd_start_time) AS product_status_scd_key, -- SCD Type 2 surrogate key for filtered results\n",
    "#     product_status_product_key,\n",
    "#     product_status_status,\n",
    "#     scd_start_time,\n",
    "#     scd_end_time\n",
    "# FROM scd_table\n",
    "# WHERE is_active = TRUE\n",
    "# AND (cdc_log_position IS NULL OR cdc_log_position > '0');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stored_procedure_scd_type2 = f\"\"\"\n",
    "# CREATE OR REPLACE PROCEDURE {stored_procedure_name.upper()}(cdc_log_position INT DEFAULT NULL)\n",
    "# RETURNS STRING\n",
    "# LANGUAGE SQL\n",
    "# AS\n",
    "# $$\n",
    "# DECLARE\n",
    "#     sql_query STRING;\n",
    "# BEGIN\n",
    "#     -- Step 1: Construct the SQL query with CTEs\n",
    "#     sql_query := '\n",
    "#     MERGE INTO {snowflake_database.upper()}.{snowflake_schema.upper()}.{snowflake_product_status_hst.upper()} AS target\n",
    "#     USING (\n",
    "#         WITH \n",
    "#         deduplicated_cdc AS (\n",
    "#             SELECT DISTINCT\n",
    "#                 product_key,\n",
    "#                 status,\n",
    "#                 json_extract_path_text(change_type, ''type'') AS change_type,\n",
    "#                 change_time,\n",
    "#                 cdc_log_position\n",
    "#             FROM {snowflake_database.upper()}.{snowflake_schema.upper()}.{snowflake_product_status_cdc.upper()}\n",
    "#             WHERE change_time IS NOT NULL\n",
    "#         ),\n",
    "        \n",
    "#         hash_table_1 AS (\n",
    "#             SELECT *,\n",
    "#                 CASE \n",
    "#                     WHEN change_type != ''DELETE'' THEN HASH(product_key, status)\n",
    "#                     ELSE HASH(product_key, status, change_time, change_type)\n",
    "#                 END AS _hash_1,\n",
    "#                 LAG(_hash_1) OVER (PARTITION BY product_key ORDER BY change_time) AS _previous_hash_1,\n",
    "#                 COALESCE(_hash_1 != _previous_hash_1, TRUE) AS _valued_changed_1\n",
    "#             FROM deduplicated_cdc\n",
    "#         ),\n",
    "        \n",
    "#         hash_table_2 AS (\n",
    "#             SELECT * \n",
    "#             FROM hash_table_1 \n",
    "#             WHERE _valued_changed_1 = ''TRUE''\n",
    "#         ),\n",
    "        \n",
    "#         final_table AS (\n",
    "#             SELECT ht2.*,\n",
    "#                 LAG(status) OVER (PARTITION BY product_key ORDER BY change_time) AS _previous_status,\n",
    "#                 CASE \n",
    "#                     WHEN ht2.change_type = ''DELETE'' AND ht2.status = _previous_status THEN FALSE\n",
    "#                     ELSE TRUE\n",
    "#                 END AS is_active\n",
    "#             FROM hash_table_2 AS ht2\n",
    "#         ),\n",
    "\n",
    "#         scd_table AS (\n",
    "#             SELECT \n",
    "#                 product_key AS product_status_product_key,\n",
    "#                 status AS product_status_status,\n",
    "#                 CAST(change_time AS TIMESTAMP_NTZ) AS scd_start_time,\n",
    "#                 CASE \n",
    "#                     WHEN is_active = FALSE THEN CAST(change_time AS TIMESTAMP_NTZ)\n",
    "#                     ELSE CAST(\n",
    "#                         COALESCE(\n",
    "#                             LEAD(change_time) OVER (PARTITION BY product_key ORDER BY change_time),\n",
    "#                             TIMESTAMP ''2999-01-01 00:00:00''\n",
    "#                         ) AS TIMESTAMP_NTZ\n",
    "#                     )\n",
    "#                 END AS scd_end_time,\n",
    "#                 is_active,\n",
    "#                 cdc_log_position -- Include CDC_LOG_POSITION here\n",
    "#             FROM final_table\n",
    "#         )\n",
    "#         SELECT \n",
    "#             -- ROW_NUMBER() OVER (ORDER BY product_status_product_key, scd_start_time) AS product_status_scd_key,\n",
    "#             ROW_NUMBER() OVER (PARTITION BY product_status_product_key ORDER BY scd_start_time) AS product_status_scd_key,\n",
    "#             product_status_product_key,\n",
    "#             product_status_status,\n",
    "#             scd_start_time,\n",
    "#             scd_end_time,\n",
    "#             cdc_log_position\n",
    "#         FROM scd_table\n",
    "#         WHERE is_active = TRUE\n",
    "#         -- AND (cdc_log_position IS NULL OR cdc_log_position > ' || COALESCE(cdc_log_position::STRING, 'NULL') || ')\n",
    "#     ) AS source\n",
    "#     ON target.product_status_product_key = source.product_status_product_key\n",
    "#        -- AND target.product_status_scd_key = source.product_status_scd_key\n",
    "#        AND target.product_status_status = source.product_status_status -- Check full unique conditions\n",
    "#        AND target.scd_start_time = source.scd_start_time\n",
    "#        AND target.scd_end_time = source.scd_end_time\n",
    "       \n",
    "\n",
    "#     WHEN MATCHED AND (source.cdc_log_position IS NULL OR source.cdc_log_position > ' || COALESCE(cdc_log_position::STRING, 'NULL') || ') THEN\n",
    "#         UPDATE SET\n",
    "#             -- target.product_status_scd_key = source.product_status_scd_key,\n",
    "#             target.product_status_status = source.product_status_status,\n",
    "#             target.scd_start_time = source.scd_start_time,\n",
    "#             target.scd_end_time = source.scd_end_time\n",
    "\n",
    "#     WHEN NOT MATCHED THEN\n",
    "#         INSERT (product_status_scd_key, product_status_product_key, product_status_status, scd_start_time, scd_end_time)\n",
    "#         VALUES (source.product_status_scd_key, source.product_status_product_key, source.product_status_status, source.scd_start_time, source.scd_end_time);\n",
    "#         -- INSERT (product_status_product_key, product_status_status, scd_start_time, scd_end_time)\n",
    "#         -- VALUES (source.product_status_product_key, source.product_status_status, source.scd_start_time, source.scd_end_time);\n",
    "#     ';\n",
    "\n",
    "#     -- Execute the constructed SQL query\n",
    "#     EXECUTE IMMEDIATE sql_query;\n",
    "\n",
    "#     RETURN 'CDC processing complete.';\n",
    "# END;\n",
    "# $$;\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if Stored Procedure Exists\n",
    "check_stored_procedure = f\"SELECT * FROM INFORMATION_SCHEMA.PROCEDURES;\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete_stored_procedure_scd_type2 = f\"DROP PROCEDURE IF EXISTS {snowflake_database.upper()}.{snowflake_schema.upper()}.PROCESS_CDC_SCD(INT);\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Database successfully.\n",
      "Using Schema successfully.\n",
      "Setting Role successful.\n",
      "Checking if Stored Procedured Exists.\n",
      "Stored procedure 'PROCESS_CDC_SCD' exists in 'CAIOCVELASCO.DATA_ENGINEER'.\n",
      "Stored Procedure executed for cdc_log_position=0.\n",
      "DataFrame for cdc_log_position=0:\n",
      "   PRODUCT_STATUS_SCD_KEY  PRODUCT_STATUS_PRODUCT_KEY  PRODUCT_STATUS_STATUS  \\\n",
      "0                       1                           1                     10   \n",
      "1                       2                           1                     20   \n",
      "2                       3                           1                     10   \n",
      "\n",
      "       SCD_START_TIME         SCD_END_TIME  \n",
      "0 2019-01-01 10:00:00  2019-01-01 11:00:00  \n",
      "1 2019-01-01 11:00:00  2019-01-01 12:00:00  \n",
      "2 2019-01-01 14:00:00  2999-01-01 00:00:00  \n",
      "Stored Procedure executed for cdc_log_position=0.\n",
      "DataFrame for cdc_log_position=4:\n",
      "   PRODUCT_STATUS_SCD_KEY  PRODUCT_STATUS_PRODUCT_KEY  PRODUCT_STATUS_STATUS  \\\n",
      "0                       1                           1                     10   \n",
      "1                       2                           1                     20   \n",
      "2                       3                           1                     10   \n",
      "\n",
      "       SCD_START_TIME         SCD_END_TIME  \n",
      "0 2019-01-01 10:00:00  2019-01-01 11:00:00  \n",
      "1 2019-01-01 11:00:00  2019-01-01 12:00:00  \n",
      "2 2019-01-01 14:00:00  2999-01-01 00:00:00  \n",
      "Script execution completed.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Snowflake connection context manager\n",
    "    with snowflake.connector.connect(\n",
    "        user=snowflake_user,\n",
    "        password=snowflake_password,\n",
    "        account=snowflake_account,\n",
    "        warehouse=snowflake_warehouse,\n",
    "        database=snowflake_database,\n",
    "        schema=snowflake_schema\n",
    "    ) as conn:\n",
    "        \n",
    "        # Execute operations within the context manager\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        try:            \n",
    "            cursor.execute(use_snowflake_database)              # Use Database (Set it for the user session)\n",
    "            print(\"Using Database successfully.\")\n",
    "\n",
    "            cursor.execute(use_snowflake_schema)                # Use Schema (Set it for the user session)\n",
    "            print(\"Using Schema successfully.\")\n",
    "    \n",
    "            cursor.execute(use_snowflake_role)                  # Use Role    \n",
    "            print(\"Setting Role successful.\")\n",
    "\n",
    "            # cursor.execute(delete_stored_procedure_scd_type2) # Delete Stored Procedure\n",
    "            # print(\"Stored Deleted Successfully.\")\n",
    "            \n",
    "            # cursor.execute(stored_procedure_scd_type2)          # Execute Stored Procedure\n",
    "            # print(\"Stored Procedured Executed Successfully.\")\n",
    "\n",
    "            print(\"Checking if Stored Procedured Exists.\")      # Check Stored Procedure\n",
    "            cursor.execute(check_stored_procedure)              \n",
    "            result = cursor.fetchall()                          # Fetch the result\n",
    "            if result:                                          # Check if the result is empty\n",
    "                print(f\"Stored procedure '{stored_procedure_name}' exists in '{snowflake_database.upper()}.{snowflake_schema.upper()}'.\")\n",
    "            else:\n",
    "                print(f\"Stored procedure '{stored_procedure_name}' does not exist in schema '{snowflake_database.upper()}.{snowflake_schema.upper()}'.\")\n",
    "               \n",
    "            cursor.execute(f\"CALL {snowflake_database.upper()}.{snowflake_schema.upper()}.{stored_procedure_name}(0)\")\n",
    "            print(\"Stored Procedure executed for cdc_log_position=0.\")\n",
    "\n",
    "            # Query and load the table into a DataFrame\n",
    "            cursor.execute(\"SELECT * FROM PRODUCT_STATUS_HST\")\n",
    "            data_cdc_0 = cursor.fetchall()\n",
    "            columns = [desc[0] for desc in cursor.description]\n",
    "            df_cdc_0 = pd.DataFrame(data_cdc_0, columns=columns)\n",
    "            print(\"DataFrame for cdc_log_position=0:\")\n",
    "            print(df_cdc_0)\n",
    "\n",
    "            cursor.execute(f\"CALL {snowflake_database.upper()}.{snowflake_schema.upper()}.{stored_procedure_name}(2)\")\n",
    "            print(\"Stored Procedure executed for cdc_log_position=0.\")\n",
    "\n",
    "            # Query and load the table into a DataFrame\n",
    "            cursor.execute(\"SELECT * FROM PRODUCT_STATUS_HST\")\n",
    "            data_cdc_4 = cursor.fetchall()\n",
    "            columns = [desc[0] for desc in cursor.description]\n",
    "            df_cdc_4 = pd.DataFrame(data_cdc_4, columns=columns)\n",
    "            print(\"DataFrame for cdc_log_position=4:\")\n",
    "            print(df_cdc_4)\n",
    "\n",
    "        except snowflake.connector.errors.ProgrammingError as e:\n",
    "                print(f\"Snowflake ProgrammingError: {e}\")\n",
    "\n",
    "        finally:\n",
    "            cursor.close()    \n",
    "\n",
    "except snowflake.connector.errors.DatabaseError as e:\n",
    "    print(f\"Snowflake DatabaseError: {e}\")\n",
    "\n",
    "print(\"Script execution completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breaking Down the SCD Type 2 Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame for deduplicated_cdc:\n",
      "   PRODUCT_KEY  STATUS CHANGE_TYPE         CHANGE_TIME  CDC_LOG_POSITION\n",
      "0            1      10      INSERT 2019-01-01 10:00:00                 1\n",
      "1            1      10      UPDATE 2019-01-01 10:30:00                 2\n",
      "2            1      20      UPDATE 2019-01-01 11:00:00                 3\n",
      "3            1      20      DELETE 2019-01-01 12:00:00                 4\n",
      "4            1      10      INSERT 2019-01-01 14:00:00                 5\n",
      "DataFrame for hash_table_1:\n",
      "   PRODUCT_KEY  STATUS CHANGE_TYPE         CHANGE_TIME  CDC_LOG_POSITION  \\\n",
      "0            1      10      INSERT 2019-01-01 10:00:00                 1   \n",
      "1            1      10      UPDATE 2019-01-01 10:30:00                 2   \n",
      "2            1      20      UPDATE 2019-01-01 11:00:00                 3   \n",
      "3            1      20      DELETE 2019-01-01 12:00:00                 4   \n",
      "4            1      10      INSERT 2019-01-01 14:00:00                 5   \n",
      "\n",
      "               _HASH_1  _PREVIOUS_HASH_1  _VALUED_CHANGED_1  \n",
      "0  -423297550457634805               NaN               True  \n",
      "1  -423297550457634805     -4.232976e+17              False  \n",
      "2  9220644093932630966     -4.232976e+17               True  \n",
      "3 -8786965074795470410      9.220644e+18               True  \n",
      "4  -423297550457634805     -8.786965e+18               True  \n"
     ]
    }
   ],
   "source": [
    "with snowflake.connector.connect(\n",
    "    user=snowflake_user,\n",
    "    password=snowflake_password,\n",
    "    account=snowflake_account,\n",
    "    warehouse=snowflake_warehouse,\n",
    "    database=snowflake_database,\n",
    "    schema=snowflake_schema\n",
    ") as conn:\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    try:\n",
    "        # 1. Execute deduplicated_cdc CTE\n",
    "        deduplicated_cdc_query = f\"\"\"\n",
    "        SELECT DISTINCT\n",
    "            product_key,\n",
    "            status,\n",
    "            json_extract_path_text(change_type, 'type') AS change_type,\n",
    "            change_time,\n",
    "            cdc_log_position\n",
    "        FROM {snowflake_database.upper()}.{snowflake_schema.upper()}.{snowflake_product_status_cdc.upper()}\n",
    "        WHERE change_time IS NOT NULL;\n",
    "        \"\"\"\n",
    "        cursor.execute(deduplicated_cdc_query)\n",
    "        data_deduplicated_cdc = cursor.fetchall()\n",
    "        columns = [desc[0] for desc in cursor.description]\n",
    "        df_deduplicated_cdc = pd.DataFrame(data_deduplicated_cdc, columns=columns)\n",
    "        print(\"DataFrame for deduplicated_cdc:\")\n",
    "        print(df_deduplicated_cdc)\n",
    "        \n",
    "        # 2. Execute hash_table_1 CTE\n",
    "        hash_table_1_query = \"\"\"\n",
    "        WITH \n",
    "        deduplicated_cdc AS (\n",
    "            SELECT DISTINCT\n",
    "                product_key,\n",
    "                status,\n",
    "                json_extract_path_text(change_type, 'type') AS change_type,\n",
    "                change_time,\n",
    "                cdc_log_position\n",
    "            FROM CAIOCVELASCO.DATA_ENGINEER.PRODUCT_STATUS_CDC\n",
    "            WHERE change_time IS NOT NULL\n",
    "        ),\n",
    "        \n",
    "        hash_table_1 AS (\n",
    "            SELECT *,\n",
    "                CASE \n",
    "                    WHEN change_type != 'DELETE' THEN HASH(product_key, status)\n",
    "                    ELSE HASH(product_key, status, change_time, change_type)\n",
    "                END AS _hash_1,\n",
    "                LAG(_hash_1) OVER (PARTITION BY product_key ORDER BY change_time) AS _previous_hash_1,\n",
    "                COALESCE(_hash_1 != _previous_hash_1, TRUE) AS _valued_changed_1\n",
    "            FROM deduplicated_cdc\n",
    "        )\n",
    "        select * from hash_table_1;\n",
    "        \"\"\"\n",
    "        cursor.execute(hash_table_1_query)\n",
    "        data_hash_table_1 = cursor.fetchall()\n",
    "        columns = [desc[0] for desc in cursor.description]\n",
    "        df_hash_table_1 = pd.DataFrame(data_hash_table_1, columns=columns)\n",
    "        print(\"DataFrame for hash_table_1:\")\n",
    "        print(df_hash_table_1)\n",
    "\n",
    "        # # 3. Execute hash_table_2 CTE\n",
    "        # hash_table_2_query = \"\"\"\n",
    "        # SELECT * \n",
    "        # FROM hash_table_1 \n",
    "        # WHERE _valued_changed_1 = 'TRUE'\n",
    "        # \"\"\"\n",
    "        # cursor.execute(hash_table_2_query)\n",
    "        # data_hash_table_2 = cursor.fetchall()\n",
    "        # columns = [desc[0] for desc in cursor.description]\n",
    "        # df_hash_table_2 = pd.DataFrame(data_hash_table_2, columns=columns)\n",
    "        # print(\"DataFrame for hash_table_2:\")\n",
    "        # print(df_hash_table_2)\n",
    "\n",
    "        # # 4. Execute final_table CTE\n",
    "        # final_table_query = \"\"\"\n",
    "        # SELECT ht2.*,\n",
    "        #     LAG(status) OVER (PARTITION BY product_key ORDER BY change_time) AS _previous_status,\n",
    "        #     CASE \n",
    "        #         WHEN ht2.change_type = 'DELETE' AND ht2.status = _previous_status THEN FALSE\n",
    "        #         ELSE TRUE\n",
    "        #     END AS is_active\n",
    "        # FROM hash_table_2 AS ht2\n",
    "        # \"\"\"\n",
    "        # cursor.execute(final_table_query)\n",
    "        # data_final_table = cursor.fetchall()\n",
    "        # columns = [desc[0] for desc in cursor.description]\n",
    "        # df_final_table = pd.DataFrame(data_final_table, columns=columns)\n",
    "        # print(\"DataFrame for final_table:\")\n",
    "        # print(df_final_table)\n",
    "\n",
    "        # # 5. Execute scd_table CTE\n",
    "        # scd_table_query = \"\"\"\n",
    "        # SELECT \n",
    "        #     product_key AS product_status_product_key,\n",
    "        #     status AS product_status_status,\n",
    "        #     CAST(change_time AS TIMESTAMP_NTZ) AS scd_start_time,\n",
    "        #     CASE \n",
    "        #         WHEN is_active = FALSE THEN CAST(change_time AS TIMESTAMP_NTZ)\n",
    "        #         ELSE CAST(\n",
    "        #             COALESCE(\n",
    "        #                 LEAD(change_time) OVER (PARTITION BY product_key ORDER BY change_time),\n",
    "        #                 TIMESTAMP '2999-01-01 00:00:00'\n",
    "        #             ) AS TIMESTAMP_NTZ\n",
    "        #         )\n",
    "        #     END AS scd_end_time,\n",
    "        #     is_active,\n",
    "        #     cdc_log_position\n",
    "        # FROM final_table\n",
    "        # \"\"\"\n",
    "        # cursor.execute(scd_table_query)\n",
    "        # data_scd_table = cursor.fetchall()\n",
    "        # columns = [desc[0] for desc in cursor.description]\n",
    "        # df_scd_table = pd.DataFrame(data_scd_table, columns=columns)\n",
    "        # print(\"DataFrame for scd_table:\")\n",
    "        # print(df_scd_table)\n",
    "\n",
    "        # # 6. Final query\n",
    "        # final_query = \"\"\"\n",
    "        # SELECT \n",
    "        #     ROW_NUMBER() OVER (PARTITION BY product_status_product_key ORDER BY scd_start_time) AS product_status_scd_key,\n",
    "        #     product_status_product_key,\n",
    "        #     product_status_status,\n",
    "        #     scd_start_time,\n",
    "        #     scd_end_time,\n",
    "        #     cdc_log_position\n",
    "        # FROM scd_table\n",
    "        # WHERE is_active = TRUE\n",
    "        # \"\"\"\n",
    "        # cursor.execute(final_query)\n",
    "        # data_final = cursor.fetchall()\n",
    "        # columns = [desc[0] for desc in cursor.description]\n",
    "        # df_final = pd.DataFrame(data_final, columns=columns)\n",
    "        # print(\"Final DataFrame:\")\n",
    "        # print(df_final)\n",
    "        \n",
    "    except snowflake.connector.errors.ProgrammingError as e:\n",
    "        print(f\"Snowflake ProgrammingError: {e}\")\n",
    "\n",
    "    finally:\n",
    "        cursor.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Find distinct Products for a given state and date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define query\n",
    "query_0 = f\"\"\"\n",
    "SELECT DISTINCT product_status_product_key AS product_key\n",
    "FROM {snowflake_database.upper()}.{snowflake_schema.upper()}.{snowflake_product_status_hst.upper()}\n",
    "WHERE product_status_status = '10'  -- Replace '10' with the actual state you want to test\n",
    "  AND scd_start_time <= CAST('2019-01-01' AS TIMESTAMP_NTZ) + INTERVAL '1 DAY' - INTERVAL '1 SECOND'  -- Replace '2024-10-29' with your desired test date\n",
    "  AND scd_end_time >= CAST('2019-01-01' AS TIMESTAMP_NTZ);  -- Replace '2024-10-29' with the same date as above\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Check for Existence of Product Keys\n",
    "# Ensure that all unique product keys in the CDC table exist in the SCD table.\n",
    "# Outcome: If any product keys are returned, it indicates that those keys are missing in the SCD table.\n",
    "query_1 = f\"\"\"\n",
    "SELECT DISTINCT cdc.product_key\n",
    "FROM {snowflake_database.upper()}.{snowflake_schema.upper()}.{snowflake_product_status_cdc.upper()} AS cdc\n",
    "LEFT JOIN {snowflake_database.upper()}.{snowflake_schema.upper()}.{snowflake_product_status_hst.upper()} AS scd\n",
    "ON cdc.product_key = scd.product_status_product_key\n",
    "WHERE scd.product_status_product_key IS NULL;\n",
    "\"\"\"\n",
    "\n",
    "# 2. Check for Duplicates in SCD\n",
    "# Ensure that there are no duplicate records for the same product key in the SCD table.\n",
    "# Outcome: If any rows are returned, it indicates that there are duplicates for those product keys in the SCD table.\n",
    "query_2 = f\"\"\"\n",
    "SELECT product_status_scd_key, product_status_product_key, product_status_status, scd_start_time, scd_end_time, COUNT(*) AS duplicate_count\n",
    "FROM {snowflake_database.upper()}.{snowflake_schema.upper()}.{snowflake_product_status_hst.upper()}\n",
    "GROUP BY product_status_scd_key, product_status_product_key, product_status_status, scd_start_time, scd_end_time\n",
    "HAVING COUNT(*) > 1;\n",
    "\"\"\"\n",
    "\n",
    "# 3. Check for Active Records\n",
    "# Verify that all active records in the SCD table (where scd_end_time is a future date, e.g., 2999-01-01) \n",
    "# correspond to entries in the CDC table. This ensures that the current status of a product is accurately represented.\n",
    "# Outcome: If there are any active records in the SCD table that do not have a matching product key in the CDC table, they will be returned, indicating a potential inconsistency in the data.\n",
    "query_3 = f\"\"\"\n",
    "SELECT DISTINCT s.product_status_product_key\n",
    "FROM {snowflake_database.upper()}.{snowflake_schema.upper()}.{snowflake_product_status_hst.upper()} s\n",
    "LEFT JOIN {snowflake_database.upper()}.{snowflake_schema.upper()}.{snowflake_product_status_cdc.upper()} c\n",
    "ON s.product_status_product_key = c.product_key\n",
    "WHERE s.scd_end_time = '2999-01-01 00:00:00' -- Active records\n",
    "  AND c.product_key IS NULL;\n",
    "\"\"\"\n",
    "\n",
    "# 4. Last Status Consistency Check\n",
    "# For each product key in the SCD, check if the status reflects the latest status from the CDC.\n",
    "# This ensures that updates in the CDC are accurately reflected in the SCD.\n",
    "query_4 = f\"\"\"\n",
    "WITH latest_cdc AS (\n",
    "    SELECT \n",
    "        product_key,\n",
    "        status AS latest_status,\n",
    "        ROW_NUMBER() OVER (PARTITION BY product_key ORDER BY change_time DESC) AS rn\n",
    "    FROM {snowflake_database.upper()}.{snowflake_schema.upper()}.{snowflake_product_status_cdc.upper()}\n",
    "),\n",
    "\n",
    "latest_scd AS (\n",
    "    SELECT \n",
    "        product_status_product_key,\n",
    "        product_status_status,\n",
    "        ROW_NUMBER() OVER (PARTITION BY product_status_product_key ORDER BY scd_start_time DESC) AS rn\n",
    "    FROM {snowflake_database.upper()}.{snowflake_schema.upper()}.{snowflake_product_status_hst.upper()}\n",
    "    WHERE scd_end_time = '2999-01-01 00:00:00'\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    c.product_key,\n",
    "    c.latest_status AS cdc_latest_status,\n",
    "    s.product_status_status AS scd_latest_status\n",
    "FROM latest_cdc c\n",
    "LEFT JOIN latest_scd s ON c.product_key = s.product_status_product_key\n",
    "WHERE c.rn = 1 \n",
    "    AND (s.rn <> 1 OR s.product_status_status IS NULL OR s.product_status_status <> c.latest_status);\n",
    "\"\"\"\n",
    "\n",
    "# 5. Consistency Check\n",
    "# This query ensures that the change types (INSERT, UPDATE, DELETE) in the CDC align with the records in the SCD.\n",
    "query_5 = f\"\"\"\n",
    "WITH deduplicated_cdc AS (\n",
    "    SELECT \n",
    "        product_key,\n",
    "        status,\n",
    "        json_extract_path_text(change_type, 'type') AS change_type,\n",
    "        change_time\n",
    "    FROM {snowflake_database.upper()}.{snowflake_schema.upper()}.{snowflake_product_status_cdc.upper()}\n",
    "    WHERE change_time IS NOT NULL\n",
    "    GROUP BY product_key, status, change_type, change_time\n",
    "),\n",
    "\n",
    "insert_check AS (\n",
    "    SELECT \n",
    "        cdc.product_key,\n",
    "        cdc.status,\n",
    "        cdc.change_type,\n",
    "        cdc.change_time\n",
    "    FROM deduplicated_cdc cdc\n",
    "    LEFT JOIN {snowflake_database.upper()}.{snowflake_schema.upper()}.{snowflake_product_status_hst.upper()} scd\n",
    "        ON cdc.product_key = scd.product_status_product_key\n",
    "        AND cdc.status = scd.product_status_status\n",
    "        AND scd.scd_end_time = '2999-01-01 00:00:00'\n",
    "    WHERE cdc.change_type = 'INSERT'\n",
    "    AND scd.product_status_product_key IS NULL\n",
    "),\n",
    "\n",
    "update_check AS (\n",
    "    SELECT \n",
    "        cdc.product_key,\n",
    "        cdc.status,\n",
    "        cdc.change_type,\n",
    "        cdc.change_time\n",
    "    FROM deduplicated_cdc cdc\n",
    "    LEFT JOIN {snowflake_database.upper()}.{snowflake_schema.upper()}.{snowflake_product_status_hst.upper()} scd\n",
    "        ON cdc.product_key = scd.product_status_product_key\n",
    "        AND cdc.status = scd.product_status_status\n",
    "    WHERE cdc.change_type = 'UPDATE'\n",
    "    AND scd.product_status_product_key IS NULL\n",
    "),\n",
    "\n",
    "delete_check AS (\n",
    "    SELECT \n",
    "        cdc.product_key,\n",
    "        cdc.status,\n",
    "        cdc.change_time\n",
    "    FROM deduplicated_cdc cdc\n",
    "    LEFT JOIN {snowflake_database.upper()}.{snowflake_schema.upper()}.{snowflake_product_status_hst.upper()} scd\n",
    "        ON cdc.product_key = scd.product_status_product_key\n",
    "    WHERE cdc.change_type = 'DELETE'\n",
    "    GROUP BY cdc.product_key, cdc.status, cdc.change_time\n",
    "    HAVING COUNT(scd.product_status_product_key) = 1\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    'INSERT' AS check_type,\n",
    "    COUNT(*) AS total_issues\n",
    "FROM insert_check\n",
    "UNION ALL\n",
    "SELECT \n",
    "    'UPDATE' AS check_type,\n",
    "    COUNT(*) AS total_issues\n",
    "FROM update_check\n",
    "UNION ALL\n",
    "SELECT \n",
    "    'DELETE' AS check_type,\n",
    "    COUNT(*) AS total_issues\n",
    "FROM delete_check;\n",
    "\"\"\"\n",
    "\n",
    "# 6. Time Range Validation\n",
    "# This check calculates the end time of one record and compares it to the start time of the next record for each product key. If the end time exceeds the next start time, it indicates overlapping records.\n",
    "# Outcome: No output means that there is no overlapping records.\n",
    "query_6 = f\"\"\"\n",
    "WITH time_ranges AS (\n",
    "    SELECT \n",
    "        product_status_product_key,\n",
    "        scd_start_time,\n",
    "        scd_end_time,\n",
    "        LEAD(scd_start_time) OVER (PARTITION BY product_status_product_key ORDER BY scd_start_time) AS next_start_time\n",
    "    FROM {snowflake_database.upper()}.{snowflake_schema.upper()}.{snowflake_product_status_hst.upper()}\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    product_status_product_key,\n",
    "    COUNT(*) AS overlapping_records\n",
    "FROM time_ranges\n",
    "WHERE scd_end_time > next_start_time\n",
    "GROUP BY product_status_product_key\n",
    "HAVING COUNT(*) > 0;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Database successfully.\n",
      "DataFrame for Query 1:\n",
      "Empty DataFrame\n",
      "Columns: [PRODUCT_KEY]\n",
      "Index: []\n",
      "DataFrame for Query 2:\n",
      "Empty DataFrame\n",
      "Columns: [PRODUCT_STATUS_SCD_KEY, PRODUCT_STATUS_PRODUCT_KEY, PRODUCT_STATUS_STATUS, SCD_START_TIME, SCD_END_TIME, DUPLICATE_COUNT]\n",
      "Index: []\n",
      "DataFrame for Query 3:\n",
      "Empty DataFrame\n",
      "Columns: [PRODUCT_STATUS_PRODUCT_KEY]\n",
      "Index: []\n",
      "DataFrame for Query 4:\n",
      "Empty DataFrame\n",
      "Columns: [PRODUCT_KEY, CDC_LATEST_STATUS, SCD_LATEST_STATUS]\n",
      "Index: []\n",
      "DataFrame for Query 5:\n",
      "  CHECK_TYPE  TOTAL_ISSUES\n",
      "0     INSERT             0\n",
      "1     UPDATE             0\n",
      "2     DELETE             0\n",
      "DataFrame for Query 6:\n",
      "Empty DataFrame\n",
      "Columns: [PRODUCT_STATUS_PRODUCT_KEY, OVERLAPPING_RECORDS]\n",
      "Index: []\n",
      "Script execution completed.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Snowflake connection context manager\n",
    "    with snowflake.connector.connect(\n",
    "        user=snowflake_user,\n",
    "        password=snowflake_password,\n",
    "        account=snowflake_account,\n",
    "        warehouse=snowflake_warehouse,\n",
    "        database=snowflake_database,\n",
    "        schema=snowflake_schema\n",
    "    ) as conn:\n",
    "        \n",
    "        # Execute operations within the context manager\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        try:            \n",
    "            cursor.execute(use_snowflake_database)  # Use Database (Set it for the user session)\n",
    "            print(\"Using Database successfully.\")\n",
    "            \n",
    "            # Query 1 Execution and DataFrame Conversion\n",
    "            cursor.execute(query_1)\n",
    "            data_1 = cursor.fetchall()\n",
    "            columns_1 = [desc[0] for desc in cursor.description]\n",
    "            df_query_1 = pd.DataFrame(data_1, columns=columns_1)\n",
    "            print(\"DataFrame for Query 1:\")\n",
    "            print(df_query_1)\n",
    "\n",
    "            # Query 2 Execution and DataFrame Conversion\n",
    "            cursor.execute(query_2)\n",
    "            data_2 = cursor.fetchall()\n",
    "            columns_2 = [desc[0] for desc in cursor.description]\n",
    "            df_query_2 = pd.DataFrame(data_2, columns=columns_2)\n",
    "            print(\"DataFrame for Query 2:\")\n",
    "            print(df_query_2)\n",
    "\n",
    "            # Query 3 Execution and DataFrame Conversion\n",
    "            cursor.execute(query_3)\n",
    "            data_3 = cursor.fetchall()\n",
    "            columns_3 = [desc[0] for desc in cursor.description]\n",
    "            df_query_3 = pd.DataFrame(data_3, columns=columns_3)\n",
    "            print(\"DataFrame for Query 3:\")\n",
    "            print(df_query_3)\n",
    "\n",
    "            # Query 4 Execution and DataFrame Conversion\n",
    "            cursor.execute(query_4)\n",
    "            data_4 = cursor.fetchall()\n",
    "            columns_4 = [desc[0] for desc in cursor.description]\n",
    "            df_query_4 = pd.DataFrame(data_4, columns=columns_4)\n",
    "            print(\"DataFrame for Query 4:\")\n",
    "            print(df_query_4)\n",
    "\n",
    "            # Query 5 Execution and DataFrame Conversion\n",
    "            cursor.execute(query_5)\n",
    "            data_5 = cursor.fetchall()\n",
    "            columns_5 = [desc[0] for desc in cursor.description]\n",
    "            df_query_5 = pd.DataFrame(data_5, columns=columns_5)\n",
    "            print(\"DataFrame for Query 5:\")\n",
    "            print(df_query_5)\n",
    "\n",
    "            # Query 6 Execution and DataFrame Conversion\n",
    "            cursor.execute(query_6)\n",
    "            data_6 = cursor.fetchall()\n",
    "            columns_6 = [desc[0] for desc in cursor.description]\n",
    "            df_query_6 = pd.DataFrame(data_6, columns=columns_6)\n",
    "            print(\"DataFrame for Query 6:\")\n",
    "            print(df_query_6)\n",
    "\n",
    "        except snowflake.connector.errors.ProgrammingError as e:\n",
    "            print(f\"Snowflake ProgrammingError: {e}\")\n",
    "\n",
    "        finally:\n",
    "            cursor.close()    \n",
    "\n",
    "except snowflake.connector.errors.DatabaseError as e:\n",
    "    print(f\"Snowflake DatabaseError: {e}\")\n",
    "\n",
    "print(\"Script execution completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
